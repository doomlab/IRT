---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "Erin M. Buchanan"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "326 Market St., Harrisburg, PA 17101"
    email         : "ebuchanan@harrisburgu.edu"
  - name          : "Jeffrey Pavlacic"
    affiliation   : "2"
  - name          : "Becca Huber"
    affiliation   : "3"
  - name          : "Alyssa Counsell"
    affiliation   : "4"

affiliation:
  - id            : "1"
    institution   : "Harrisburg University of Science and Technology"
  - id            : "2"
    institution   : "University of Mississippi"
  - id            : "3"
    institution   : "Idaho State University"
  - id            : "4"
    institution   : "Ryerson University"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["MGCFA paper.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : yes

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
# chunk options 
knitr::opts_chunk$set(echo = FALSE, cache = TRUE)

## Seed for random number generation
set.seed(37563)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

# Libraries
# devtools::install_github("crsh/papaja")
library(papaja)
library(memisc)

# Functions

# Turn off scipen
options(scipen = 999)
```

MAKE A PACKRAT 
- figure out how to reference other markdowns

Classify by sample size, classify by scale size 
random versus not random (drop paper)
See if/where it breaks 
- configural
- metric
- scalar
- strict residuals

[@Buchanan2002] says that stuff is stuff and stuff. [@Buchanan2005] said more stuff. This file needs an update. 

## Measure Randomization

Different measurement modalities (e.g., paper vs. online surveys) frequently show equivalent results in terms of item responses (Deutskens et al., 2006). Further, item randomization procedures exhibit null effects in terms of varying scale psychometrics (Buchanan, Foreman, Johnson, Pavlacic, Swadley, & Schulenberg, 2018). Measures are administered in different ways with different procedures and will typically yield nonsignificant differences in terms of differences across administration type (T. Buchanan et al., 2006; Meyerson & Tyron, 2003; Ruyter & Wetzels, 2006). But, a less-examined area of scale psychometrics relates to how heterogeneous administration modalities affect factor structure. For example, T. Buchanan et al. (2005) found that factor structure did not replicate in online vs. mailed surveys. This phenomenon has not been examined within the context of item randomization, despite this method commonly being used to counterbalance measures and control for order effects (Keppel & Wickens, 2004). One area where item administrationhas the potential to affect factor structure is meaning in life. 
##def will add more here..just need to figure out direction to take it. do we want to talk more about item randomization? focus more on different administration modalities? 

##Meaning in Life 

Meaning in life refers to an individual's understanding of his or her life, complemented by desired goals (Steger, Bundick, & Yeager, 2014). Meaning occurs through goal achievement, as well as positive interactions with others or the environment (Frankl, 1966, 1984). The concept of meaning is prevalent across different contexts, including natural disaster survivors (Van Tongeren et al., 2018) and those attending college for the first time (Bronk, Riches, & Mangan, 2018) among countless others (for a review, see Brandstetter, Baumann, Borasio, & Fegg, 2012). Individuals lacking meaning are at risk for developing various forms of psychopathology, such as depression (Beck, 1967) and anxiety (Bernard et al., 2017). Given the relavence of meaning to well-being and psychological suffering, understanding how to measure meaning in life is crucial to intervention and research efforts. Empirically-validated measures of meaning in life will help researchers to better understand the construct itself, as well as how it relates to treatment outcome. 
##feel pretty good about this paragraph - think an introduction is all we need here, then move more into why MIL assessment is poor

The concept of meaning in life is measured in different ways, and coming to conclusions regarding meaning in life literature can be difficult (Cosco et al., 2017). Within the 21st century alone, Hicks and Routledge (2013) catalogued 59 meaning in life measures targeting different domains (e.g., search for meaning, breadth, depth) and factor structures. For example, Ryff and Singer (1998) conceptualize meaning as dedicating time towards personal goals, while Battista and Almond (1973) consider meaning to be related to a sense of coherence or understanding. Still, others consider meaning in life as life significance (Crumbaugh & Maholick, 1964), while Steger, Frazier, Oishi, and Kaler (2006) posit meaning to have two components (i.e., Presence of Meaning and Search for Meaning). Demographically, meaning also varies across gender (Chamberlain & Zika, 1998). Recently, researchers have argued as to whether meaning should be differentiated from the concept of purpose (Martela & Steger, 2016). Bronk, Riches, and Mangan (2018) consider meaning to be a component of purpose. Meaning in life measures have therefore been criticized for their lack of objectivity (Dyck, 1987; Frazier, Oishi, & Steger, 2003; Garfield, 1973; Klinger, 1977; Steger et al., 2006; Yalom, 1980) and heterogeneity. Understanding the factor structure of individual meaning in life measures is crucial to facilitating clinical work and research. One avenue that offers this opportunity are factor-analytic techniques. 

## Multi-Group Confirmatory Factor Analysis # erin this is where I might be going off topic to 
#what we are doing now vs. what we did before so feel free to edit

While meaning in life measures offer an interesting opportunity to determine whether measures yield different results across demographics and administration modalities, this topic is of interest to researchers more generally. For example, how is the factor structure of a measure supported across modalities? What about across demographically-diverse samples? Multi-group Confirmatory Factor Analysis (MGCFA) applies principles from Confirmatory Factor Analysis to different groups across a measure of interest. A careful examination of measurement variance can allow the researcher to determine whether the measure yield similar attributions across groups (Beajean, 2014). Typically, MGCFAs are conducted in a stepwise approach, first by examining configural invariance. Also referred for as "equal form invariance," configural invariance afford the researcher an opportunity to statistically determine whether factor loadings are indential across specified groups (e.g., male vs. female). Then, metric invariance determines whether there is a significant difference. Assuming our model does not significantly differ in CFI after examining metric invariance (CFI difference must be less < .01), researchers generally conduct an analysis of scalar invariance. Scalar invariance examines indicator intercepts and determines whether or not these are equal across groups. Additionally, scale invariance determines whether or not group membership influences raw scores. Our analyses present noninvariant questions across random/non-random groups so that researchers are better able to decide whether or not it would be prudent to randomize question order. This section presents a summary of MGCFA and the rationale for its usage. It is important to conduct this type of analysis in order to improve construct validity. 
##need to get a flow going in this paragraph but want to make sure I'm heading in the rigth direction with how I'm explaining this

## Goals of Present Study

We sought to conduct MGCFA on a variety of meaning in life measures and examine measurement invariance acorss these measures. A more collectivist view of meaning in life measures can facilitate sound assessment tools for clinicians and researchers. Further, this approach allowed us to understand the effects of item randomization on factor structure. This study sought to examine scale-delivery type (random vs. not random) in order to conclude whether or not randomization of different meaning in life measures produces different results in regards to factor structure of said scales. Specifically, we initially utilized a stepwise approach to examine model fit across all groups (both random and non-random). Then, data were into both random and non-random data in order to examine model fit across these individual groups. Each group provides the researcher with a set of fit indices by which to examine model fit. The rationale for conducting such an analysis is to discover whether or not each group produces less than desired fit statistics. With this information, the researcher is able to tell whether or not different group reports differently on the given scale. Regardless of model fit, we continued with the suggested stepwise approach by calculating different types of invariances. 

##Scale Development - thinking we don't need this part as our readers will probably have a good 
#understanding of how this works but leaving it in case you disagree 

#Scale development typically begins with an underlying latent construct of interest to the researcher (DeVellis citation). (Olson 2010 citation) suggests compiling a list of items thought to represent the construct of interest. These items are generally evaluated by experts in the specified area. This concept is termed as construct or face validity (citation on construct or face validity). After eliminating problematic questions, data are collected and examined through classical test methods, specifically exploratory and confirmatory factor analysis (EFA; CFA; Worthington citation) or Item Response Theory methods (cite any IRT article or probably a seminal IRT article). Generally, EFA and CFA examine correlations between items in regards to how they relate to a latent construct, also termed factor. Specific items will sometimes correlate to form multiple factors, or psychological constructs, depending on the measure of interest. For example, the DASS (cite DASS or literally any other scale with multiple factors) will lead to clusters of items correlated with different underlying constructs (depression, anxiety, stress). Unfortunately, researchers will sometimes make questionable decisions in utilizing factor-analytic methods that may lead to misinterpreted measures and drastic clinical implications (mainly, an inability of a measure to actually measure what it is supposed to measure, which could lead to misdiagnosed or incorrectly diagnosed patients. I’m sure that there are other clinical implications too, but I think that meaning in life measures are generally used as a supplement to therapy. If we use measures as a supplement to therapy, like meaning in life measures, then they could inhibit our ability to enhance therapy). Specifically, Preacher & MacMallum (2002 I think – check year) showcase common mistakes made in conducting factor analyses and how they could be avoided. Specifically, researchers will mistakenly use Principal Components Analysis (PCA) and will keep eigenvalues that are greater than 1. Additionally, they use varimax rotation (Kaiser, 1970: explain why using these things is problematic to research. Need to look into this more because I honestly don’t know much about the different types of rotations). Initially, EFA examines factor loadings in order to examine how well items correlate with a latent construct(s). When adequate factor loadings (> .300) have been achieved for each item, CFA assesses model fit by means of fit statistics (cite whoever came up with the .300 criteria). Scales demonstrating adequate model fit are then published for use in psychological assessment. Obviously, scale development is crucial and of utmost importance in accurately measuring constructs of interest. 


# Method

## Participants

```{r demographics, include = FALSE}
##Load data
master_demo <- read.csv("Demographics_Data.csv")

##Get rid of paper people
nopaper = subset(master_demo, Source < 2)

##Fixing categorical variables
nopaper$Gender = factor(nopaper$Gender,
      levels = c(9,10),
      labels = c("Male", "Female"))
      
nopaper$YearinSchool = factor(nopaper$YearinSchool,
      levels = c(1,2,3,4,5),
      labels = c("Freshman", "Sophomore", "Junior", "Senior", "Graduate/Other"))

##EthnicityPercentage
nopaper$Ethnicity = factor(nopaper$Ethnicity,
                           levels = c("Asian", "Black", "Multiple", "Other", "White"))

nopaper$Ethnicity = droplevels(nopaper$Ethnicity)

PercentEthnicity = percent(nopaper$Ethnicity)

##Means and SDs for Age
MeanAge = mean(nopaper$Age, na.rm = TRUE)
StdevAge = sd(nopaper$Age, na.rm = TRUE)

##Percent for Gender
PercentGender = percent(nopaper$Gender)

##Percent YearinSchool
PercentYearinSchool = percent(nopaper$YearinSchool)
```

  Participants in this study included `r nrow(nopaper)` students at a large Midwestern university.  Participants included 924 males (`r PercentGender["Male"]`%) and 1397 females (`r PercentGender["Female"]`%) between the ages of 15 and 55 (*M* = `r MeanAge`, *SD* = `r StdevAge`).  The study included multiple different ethnicities, made up of Asian participants (`r PercentEthnicity["Asian"]`%), Black participants (`r PercentEthnicity["Black"]`%), multiple ethnicity participants (`r PercentEthnicity["Multiple"]`%), other ethnicity participants (`r PercentEthnicity["Other"]`%), and White participants (`r PercentEthnicity["White"]`%).  The study also consisted of Freshmen (`r PercentYearinSchool["Freshman"]`%), Sophomores (`r PercentYearinSchool["Sophomore"]`%), Juniors (`r PercentYearinSchool["Junior"]`%), Seniors (`r PercentYearinSchool["Senior"]`%), and Graduate/Other students (`r PercentYearinSchool["Graduate/Other"]`%).

## Materials

need someone to make a table of the scales we used

```{r material-table, echo=FALSE, asis=TRUE}
##import dataset

scales <- read.csv("table MGCFA.csv") ##this is the file with all the scales that I made - Jeff

```

## Procedure

## Data analysis

### Data Screening

```{r results_ds_mg, child = 'MGCFA.Rmd'}
```

### MGCFA - jeff wrote this but probably wrong with new model leaving for Erin 

Multigroup Confirmatory Factor Analysis (MG-CFA) was conducted on individual meaning in life scales. This particular process involves applying CFA principles to multiple groups across different each individual scale. Delivery type (non-random vs. random) was used to examine model fit and whether or not randomization of scales produces a worse or better-fitting model. We utilized previously published standards for adding restrictions to each MG-CFA. This approach allowed us to first examine model fit across all groups. Subsequently, model fit across non-random and random groups was examined. Then, parameters were constrained in order to calculate different types of invariances. 

#### Individual Groups -jeff wrote this but probably wrong with new model leaving for Erin 

Utilizing a stepwise approach allowed us to examine model fit across individual groups by means of MG-CFA. We conducted single-group solutions based on delivery method (non-random question order vs. random question order). Questions delivered on paper were excluded for final analysis in R, as they were not part of this particular analysis. Each group provided us with a set of fit indices by which to evaluate model fit and examine whether or not scale randomization impacts factor structure across each different scale. Randomized scales not adhering to the published factor structure should warrant caution among researchers planning to deliver questions in a random format. Randomized scales adhering to published factor structure do not suggest any reason to avoid randomization of questions (Brown citation). Regardless of fit, we continued with the suggested stepwise approach by calculating different types of invariances. Each level of invariance adds restrictions to the model. 

#### Configural Invariance -jeff wrote this but probably wrong with new model leaving for Erin 

Regardless of whether or not our individualized groups both showed adequate model fit, we progressed to calculate configural invariance. Configural invariance can also be referred to as "equal form." This test allows the researcher to understand whether or not factor structure and loadings are identical across groups, in this case non-random questionnaires vs. random questionnaires. This test utilizes the same set of fit indices explained above (assuming we will add this section in the data analysis section/insert a citatio). 

#### Metric Invariance -jeff wrote this but probably wrong with new model leaving for Erin 

Regardless of whether or not equal forms was supported across groups, we then analyzed the data using metric invariance. Metric invariance examines factor loadings across groups. This analysis was supported if this test of invariance did not differ significantly from configural invariance. In order to meet this assumption, $\Delta$CFI < .01. 

#### Scalar Invariance -jeff wrote this but probably wrong with new model leaving for Erin 

Assuming that metric invariance did provide a large enough decrease in CFI, we then tested scalar invariance. Scalar invariance examines indicator intercepts and determines whether or not these are equal across groups. Additionally, scalar invariance determines whether or not group membership influences a role in raw scores across groups. If the change in CFI is not equal to or greater than .01, this assumption has been met. As with metric invariance, this analysis was supported if the test of invariance did not differ significantly from configural invariance. 

#### Partial Invariance =jeff wrote this but probably wrong with new model leaving for Erin 

Different methods have been utilized for scales that differ when utilizing the stepwise method for conducting the different types of invariances. The scale can either be abandoned or the noninvariant items removed for further analyses. This may affect construct validity as well as the theory behind the scale (Cheung & Rensvold, 1999). We relaxes constructs of noninvariant items for the remainder of analysis, as suggested by Brown (2006) & Byrne et al. (1989). 

# Results

# Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
