---
title: "Scale Results"
author: "Erin M. Buchanan"
date: "10/25/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
##libraries
library(lavaan)
library(semPlot)
library(semTools)
library(car)
library(mice)
library(knitr)
options(scipen = 999)
library(kableExtra)
library(psytabs)
library(papaja)
percentmiss = function(x){ sum(is.na(x))/length(x) *100 }

```

```{r saveddata, echo=FALSE, results = 'asis'}

##create a table here
##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint = matrix(NA, nrow = 45, ncol = 9)
tableimport = read.csv("table MGCFA.csv")
#names(tableimport)

colnames(tableprint) = c("Scale Name", "Number of Scale Points", "N Not Random", "N Random", "Reliability", "Number of Items", "Number of Subscales", "Partial Invariance", "Where")

##need to add, "Did it Break Down(Y/N)", "Where it Broke Down", "Partial Invariance (Y/N)", "Citation Counts", "Publication Year"
tableprint[ , 1] = as.character(tableimport$scalename)
tableprint[ , 2] = as.character(tableimport$scaling)
tableprint[ , 5] = as.character(tableimport$reliability) 
tableprint[ , 7] = as.character(tableimport$subscales)

kable(tableprint, caption = "Final Table") %>%
  column_spec(1, width = "5cm")

```

# Boredom Proness Scale
citation will go here

```{r BPS, include=FALSE}
setwd("~/Desktop")
master = read.csv("all_data_combined_edit.csv") ##might need to make an import data chunk maybe?
summary(master)

##Reverse Code
##in the qualtrics true = 1, false = 2
##recode the false ones so that all 1s get 1 point, 
##all 2s should be coded as zero points

##make a new dataset with the columns we need 
bps = master[ , c(409:436, 955, 956, 14)]

bps$BP1 = recode(bps$BP1, "1='2'; 2='1'")
bps$BP7 = recode(bps$BP7, "1='2'; 2='1'")
bps$BP8 = recode(bps$BP8, "1='2'; 2='1'")
bps$BP11 = recode(bps$BP11, "1='2'; 2='1'")
bps$BP13 = recode(bps$BP13, "1='2'; 2='1'")
bps$BP15 = recode(bps$BP15, "1='2'; 2='1'")
bps$BP18 = recode(bps$BP18, "1='2'; 2='1'")
bps$BP22 = recode(bps$BP22, "1='2'; 2='1'")
bps$BP23 = recode(bps$BP23, "1='2'; 2='1'")
bps$BP24 = recode(bps$BP24, "1='2'; 2='1'")

##Make everything 0 and 1 to add up correctly
##true is 1, false is 2, so subtract 2 
names(bps)
bps[ , 1:28] = 2 - bps[ , 1:28]

####DATA SCREENING####

##Missing Data##
##Going by rows ONLY
notypos = bps
names(notypos)
missing = apply(notypos[ , 1:28], 1, percentmiss) 
table(missing)

##Replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##Figure out the columns to exclude
##source, year, partno
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(29,30,31)]
dontcolumn = replacepeople[ , c(1:28)]

##MICE
tempnomiss = mice(replacecolumn)
nomiss = complete(tempnomiss, 1)
summary(nomiss)

##(By your powers) Combine (I am Captain Planet!)
filledin_none = cbind(dontcolumn, nomiss)
summary(filledin_none)

##Small note: When MICE is run on this project the YEAR column
##is moved from the last column to the third column.
##This trend is not observed with data that does not need
##to be MICE'd. All code exluding ID columns has been corrected
##for this. 
#~Hannah 

##Outliers##
##Mahal

mahal = mahalanobis(filledin_none[ , -c(29:31)], 
                    colMeans(filledin_none[ , -c(29:31)], na.rm = TRUE),
                    cov(filledin_none[ , -c(29:31)], use="pairwise.complete.obs"))

summary(mahal)
cutoff = qchisq(.999,ncol(filledin_none[ , -c(29:31)])) 
summary(mahal < cutoff)
noout = filledin_none[ mahal < cutoff, ]

##Additivity: correlations
correlations = cor(noout[,-c(29:31)], use="pairwise.complete.obs")
symnum(correlations)

##Make the random stuff & exclude the ID columns 
random = rchisq(nrow(noout), 7)
fake = lm(random~., data=noout[ , -c(29:31)])

##Linearity plot
##Create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##Multivariate normality
hist(standardized, breaks=15)

##Homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring
##This scale is true/false. The number of True and False for each question quantified below.
score = rowSums(noout[ , 1:28])
summary(score)

##Factoring source##
#Zero = notrandom, One = random, Two = paper
table(bps$source)
nooutnop = subset(noout, source != 'paper') ##excludes paper
nomissnop = subset(filledin_none, source != 'paper') ##excludes paper

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, source == 'random')

####overall cfa everyone together##
overallmodel = '
BP =~ BP1 + BP2 + BP3 + BP4 + BP5 + BP6 + BP7 + BP8 + 
      BP9 + BP10 + BP11 + BP12 + BP13 + BP14 + BP15 + 
      BP16 + BP17 + BP18 + BP19 + BP20 + BP21 + BP22 + 
      BP23 + BP24 + BP25 + BP26 + BP27 + BP28
'

overall.fit = cfa(overallmodel, 
                  data=nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

####separate group models####
##notrandom
overall.fit.nr = cfa(overallmodel, 
                    data=notrandom, 
                    meanstructure = TRUE)

summary(overall.fit.nr, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

##random
overall.fit.r = cfa(overallmodel, 
                    data=random, 
                    meanstructure = TRUE)

summary(overall.fit.r, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)


####multi group testing####
###measurement invariance

multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = "source",
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)

tabletemp = measurementInvarianceTable(multisteps)
tabletemp = tabletemp[-5 , ]
if (sum(is.numeric(tabletemp$Dcfi > .01)) > 0) {PI = "Y"} else {PI = "N"}
if (PI == "Y") {
  wherebroke = rownames(tabletemp)[tabletemp$Dcfi > 0.01 ][2]
} else {wherebroke = "N/A"}

##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 
tableprint[1, c(3, 4, 6, 8, 9)] = c(nrow(notrandom), nrow(random), ncol(random[ , -c(1:3)]), PI, wherebroke)

tableprint[1, c(3, 4, 6, 8, 9)]

```

```{r BPStable, echo = FALSE, results = 'asis'}
##columns Model, N, X2, df, RMSEA, SRMR, CFI, change CFI 
tableBPS = matrix(NA, nrow = 7, ncol = 8)
##rows will be: overall model, random, not random, multigroup steps 
tableBPS[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableBPS[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableBPS[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableBPS[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableBPS[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.configural, fit.measures = fitused), 
                      "-")

tableBPS[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.loadings)["cfi"] - fitmeasures(multisteps$fit.configural)["cfi"])

tableBPS[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.intercepts)["cfi"] - fitmeasures(multisteps$fit.loadings)["cfi"])

tableBPS[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.residuals)["cfi"] - fitmeasures(multisteps$fit.intercepts)["cfi"])

tableBPS[ , 3] = printnum(as.numeric(tableBPS[ , 3]), big.mark = "")
tableBPS[ , 5:8] = printnum(as.numeric(tableBPS[ , 5:8]), gt1 = F, digits = 3)


kable(tableBPS, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))
```


```{r BPS-SF, echo=FALSE}

bpssf = master[ , c(437:448, 14, 955,956)]
summary(master)

##No reverse coded items.

####DATA SCREENING####

##Going by rows ONLY
notypos = bpssf
names(notypos)
missing = apply(notypos[ , 1:12], 1, percentmiss) 
table(missing)

##Replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##Figure out the columns to exclude
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(13:15)]
dontcolumn = replacepeople[ , c(13:15)]

##MICE not needed here. If was we would have to replace and bind
nomiss = replacepeople

##Small note: When MICE is run on this project the YEAR column
##is moved from the last column to the thrid column.
##This trend is not observed with data that does not need
##to be MICE'd. All code exluding ID columns has been corrected
##for this. 
#~Hannah 

##Outliers##
##Mahal
names(nomiss)

mahal = mahalanobis(nomiss[ , -c(13:15)], 
                    colMeans(nomiss[ , -c(13:15)], na.rm = TRUE),
                    cov(nomiss[ , -c(13:15)], use="pairwise.complete.obs"))

summary(mahal)
cutoff = qchisq(.999,ncol(nomiss[ , -c(13:15)])) 
summary(mahal < cutoff)
noout = nomiss[ mahal < cutoff, ]

##Additivity: correlations
correlations = cor(noout[,-c(13:15)], use="pairwise.complete.obs")
symnum(correlations)

##Make the random stuff & exclude the ID columns 
random = rchisq(nrow(noout), 7)
fake = lm(random~., data=noout[ , -c(13:15)])

##get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=30)

##homogeneity and homoscedasticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring
#Internal 
internal = rowSums(noout[,c("BPSF1", "BPSF3", "BPSF5", "BPSF6", "BPSF8", "BPSF9")])
summary(internal)

#External 
external = rowSums(noout[,c("BPSF2", "BPSF4", "BPSF7", "BPSF10", "BPSF11", "BPSF12")])
summary(external)

##CFA with internal + external + noout datasets / need to drop paper
nooutnop = subset(noout, source != 'paper')
nomissnop = subset(nomiss, source != 'paper')


overallmodel = '
INT =~ BPSF1 + BPSF3 + BPSF5 + BPSF6 + BPSF8 + BPSF9
EXT =~ BPSF2 + BPSF4 + BPSF7 + BPSF10 + BPSF11 + BPSF12
'
fit = cfa(overallmodel, 
          data = nomissnop, 
          meanstructure = TRUE)

summary(fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE) ##no heywood cases 
fitMeasures(fit)

table(nomissnop$source)
##all significant 
## 0 is not random 
## 1 is random 
## 2 is paper 

##subset 
random = subset(nomissnop, source == 'random')
notrandom = subset(nomissnop, Source =='not random')

##fit for random 
random.fit = cfa(overallmodel, 
                 data = random, 
                 meanstructure = TRUE)
summary(random.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)
fitMeasures(random.fit)

##fit for not random 
notrandom.fit = cfa(overallmodel, 
                 data = notrandom, 
                 meanstructure = TRUE)
summary(notrandom.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE) ##this model seems better than random, let's see where it breaks down 
fitMeasures(notrandom.fit)

##invariances 
multisteps = measurementInvariance(overallmodel, 
                      data = nomissnop, 
                      group = 'source', 
                      strict = T)

fitMeasures(multisteps$fit.configural)
fitMeasures(multisteps$fit.loadings)
fitMeasures(multisteps$fit.intercepts)
fitMeasures(multisteps$fit.residuals)
fitMeasures(multisteps$fit.means)

##loadings seem to be related between groups 

##partials f/residuals
partial = partialInvariance(multisteps, 
                            type = "strict")

partial
strictfree = partial$results
group.partial = c("BPSF3~~BPSF3")

##after letting it go 
partialstrict = measurementInvariance(overallmodel, 
                                      data = nomissnop, 
                                      group = 'source', 
                                      strict = T, 
                                      group.partial = c("BPSF3~~BPSF3"))

fitMeasures(partialstrict$fit.residuals)


##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 
tableprint[2, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1,2,15)]), nrow(random), ncol(random[ , -c(1,2,15)]), PI, wherebroke)

tableprint[2, c(3, 4, 6, 8, 9)]

```

```{r BPS-SFtable, echo = FALSE, results = 'asis'}
tableBPSSF = matrix(NA, nrow = 7, ncol = 8)
tableBPSSF[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableBPSSF[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableBPSSF[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableBPSSF[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableBPSSF[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.configural, fit.measures = fitused), 
                      "-")

tableBPSSF[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.loadings)["cfi"] - fitmeasures(multisteps$fit.configural)["cfi"])

tableBPSSF[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.intercepts)["cfi"] - fitmeasures(multisteps$fit.loadings)["cfi"])

tableBPSSF[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.residuals)["cfi"] - fitmeasures(multisteps$fit.intercepts)["cfi"])

tableBPSSF[ , 3] = printnum(as.numeric(tableBPSSF[ , 3]), big.mark = "")
tableBPSSF[ , 5:8] = printnum(as.numeric(tableBPSSF[ , 5:8]), gt1 = F, digits = 3)


kable(tableBPSSF, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))

```


```{r BRS, include=FALSE}
brs = master[ , c(850:855,14,955,956) ]
summary(master)

##Reverse coded items.
brs$BRS2 = recode(brs$BRS2, "1='5'; 2='4'; 3='3'; 4='2'; 5='1'")
brs$BRS4 = recode(brs$BRS4, "1='5'; 2='4'; 3='3'; 4='2'; 5='1'")
brs$BRS6 = recode(brs$BRS6, "1='5'; 2='4'; 3='3'; 4='2'; 5='1'")

####DATA SCREENING####

##Missing Data##

##Going by rows ONLY
notypos = brs
names(notypos)
missing = apply(notypos[ , 1:6], 1, percentmiss) 
table(missing)

##Replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##Figure out the columns to exclude
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(7:9)]
dontcolumn = replacepeople[ , c(7:9)]

##no missing data.
nomiss = replacepeople

##Outliers##
mahal = mahalanobis(nomiss[ , -c(7:9)], 
                    colMeans(nomiss[ , -c(7:9)], na.rm = TRUE),
                    cov(nomiss[ , -c(7:9)], use="pairwise.complete.obs"))
#mahal
summary(mahal)
cutoff = qchisq(.999,ncol(nomiss[ , -c(7:9)])) 
summary(mahal < cutoff)
noout = nomiss[ mahal < cutoff, ]

##additivity: correlations
correlations = cor(noout[,-c(7:9)], use="pairwise.complete.obs")
symnum(correlations)

##make the random stuff
random = rchisq(nrow(noout), 7)
##be sure here not to include the ID columns!
fake = lm(random~., data=noout[ , -c(7:9)])

##get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring
BRS <- rowSums(nomiss[, c(1:6)])
summary(BRS)

####CFA####
##subsetting data
#Zero = notrandom, One = random, Two = paper
##subset the data
nooutnop = subset(noout, source != 'paper')
nomissnop = subset(nomiss, source != 'paper')

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, Source == 'random')

####overall model for everyone together##
overallmodel = '
BRS =~
BRS1 + BRS2 + BRS3 + BRS4 + BRS5 + BRS6
'

overall.fit = cfa(model = overallmodel, 
                  data=nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

##random
overall.fit.r = cfa(overallmodel, 
                    data=random, 
                    meanstructure = TRUE)

summary(overall.fit.r, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

##notrandom
overall.fit.nr = cfa(overallmodel, 
                     data=notrandom, 
                     meanstructure = TRUE)

summary(overall.fit.nr, 
        standardized=TRUE,
        rsquare=TRUE, 
        fit.measure = TRUE)


####multi group testing####
###measurement invariance
multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = "source",
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)


##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint[3, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1,2,9)]), nrow(random), ncol(random[ , -c(1,2,9)]), PI, wherebroke)

tableprint[3, c(3, 4, 6, 8, 9)]
```

```{r BRStable, echo = FALSE, results = 'asis'}
tableBRS = matrix(NA, nrow = 7, ncol = 8)
tableBRS[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableBRS[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableBRS[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableBRS[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableBRS[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.configural, fit.measures = fitused), 
                      "-")

tableBRS[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.loadings)["cfi"] - fitmeasures(multisteps$fit.configural)["cfi"])

tableBRS[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.intercepts)["cfi"] - fitmeasures(multisteps$fit.loadings)["cfi"])

tableBRS[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.residuals)["cfi"] - fitmeasures(multisteps$fit.intercepts)["cfi"])

tableBRS[ , 3] = printnum(as.numeric(tableBRS[ , 3]), big.mark = "")
tableBRS[ , 5:8] = printnum(as.numeric(tableBRS[ , 5:8]), gt1 = F, digits = 3)


kable(tableBRS, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))

```


```{r DMS, include=FALSE}

dms = master[ ,c(449:470,14,955,956) ]


##Reverse Code. No reverse coding. Stopped here for scoring.
##fix text columns
dms$DMSTEXT8 = as.numeric(dms$DMSTEXT8)
dms$DMSTEXT11 = as.numeric(dms$DMSTEXT11)
dms$DMSTEXT13 = as.numeric(dms$DMSTEXT13)
##dr b I noticed this when fixing this one. there are a bunch of text columns other than this one. do they need to be fixed, too? leaving for now. - Jeff

####DATA SCREENING####
##Missing Data##

##Going by rows ONLY
notypos = dms
names(notypos)
missing = apply(notypos[ , 1:22], 1, percentmiss) 
table(missing)

##Replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##Figure out the columns to exclude 
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(23:25)]
dontcolumn = replacepeople[ , c(23:25)]

##MICE
tempnomiss = mice(replacecolumn)
nomiss = complete(tempnomiss, 1)
summary(nomiss)

##(By your powers) Combine (I am Captain Planet!)
filledin_none = cbind(dontcolumn, nomiss)
summary(filledin_none)

##Outliers##
##Mahal
mahal = mahalanobis(filledin_none[ , -c(23:25)], 
                    colMeans(filledin_none[ , -c(23:25)], na.rm = TRUE),
                    cov(filledin_none[ , -c(23:25)], use="pairwise.complete.obs"))

summary(mahal)
cutoff = qchisq(.999,ncol(filledin_none[ , -c(23:25)])) 
summary(mahal < cutoff)
noout = filledin_none[ mahal < cutoff, ]

##additivity: correlations
correlations = cor(noout[,-c(23:25)], use="pairwise.complete.obs")
symnum(correlations)

##make the random stuff 
random = rchisq(nrow(noout), 7)
fake = lm(random~., data=noout[ , -c(23:25)])

##get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring
##Daily Meaning average Q1 & Q2 (Col 4&5 in dataset)
daymean <- rowMeans(filledin_none[,c("DMS1", "DMS2")])
summary(daymean)

daylife <- filledin_none$DMS3
summary(daylife)

Eud <- rowSums(filledin_none[,c(5:11)])
summary(Eud)

Hed <- rowSums(filledin_none[,c(12:22)])
summary(Hed)


##MGCFA

##Factoring source##
#Zero = notrandom, One = random, Two = paper
nooutnop = subset(noout, source != 'paper')
nomissnop = subset(filledin_none, source != 'paper')

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, source == 'random')

##Model 
##we will need to exclude the two smaller subscales
##do not have enough questions for CFA
overallmodel = '
EudaimonicBehaviors =~ DMSTEXT1 + DMSTEXT2 + DMSTEXT3 + DMSTEXT4 + DMSTEXT5 + DMSTEXT6 + DMSTEXT7
HedonicBehaviors =~ DMSTEXT8 + DMSTEXT9 + DMSTEXT10 + DMSTEXT11 + DMSTEXT12 + DMSTEXT13 + DMSTEXT14 +  DMSTEXT15 + DMSTEXT16 + DMSTEXT17 + DMSTEXT18 + DMSTEXT19
'
overall.fit = cfa(overallmodel, 
                  data=nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

####separate group models####
##notrandom
overall.fit.nr = cfa(overallmodel, 
                     data=notrandom, 
                     meanstructure = TRUE)

summary(overall.fit.nr, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

##random
overall.fit.r = cfa(overallmodel, 
                    data=random, 
                    meanstructure = TRUE)

summary(overall.fit.r, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)


####multi group testing####
###measurement invariance

multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = "source",
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)

##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint[4, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1,2,3)]), nrow(random), ncol(random[ , -c(1,2,3)]), PI, wherebroke)

tableprint[4, c(3, 4, 6, 8, 9)]

```


```{r DMStable, echo = FALSE, results = 'asis'}
tableDMS = matrix(NA, nrow = 7, ncol = 8)
tableDMS[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableDMS[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableDMS[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableDMS[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableDMS[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.configural, fit.measures = fitused), 
                      "-")

tableDMS[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.loadings)["cfi"] - fitmeasures(multisteps$fit.configural)["cfi"])

tableDMS[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.intercepts)["cfi"] - fitmeasures(multisteps$fit.loadings)["cfi"])

tableDMS[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.residuals)["cfi"] - fitmeasures(multisteps$fit.intercepts)["cfi"])

tableDMS[ , 3] = printnum(as.numeric(tableDMS[ , 3]), big.mark = "")
tableDMS[ , 5:8] = printnum(as.numeric(tableDMS[ , 5:8]), gt1 = F, digits = 3)


kable(tableDMS, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))

```


```{r ELM, include=FALSE}

elm = master[ , c(740:779,14,955,956)]
summary(elm)

##Reverse Code. No Reverse Coding.

####DATA SCREENING####

##Missing Data##

##Going by rows ONLY
##here I excluded the first two columns because they were 
##included for everyone as IDs, so I don't want to count that
##as part of the percent toward what they did
notypos = elm
names(notypos)
missing = apply(notypos[ , 1:40], 1, percentmiss) 
table(missing)

##replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##figure out the columns to exclude (survey data)
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(41:43)]
dontcolumn = replacepeople[ , c(41:43)]

##let's mice it!
tempnomiss = mice(replacecolumn)
nomiss = complete(tempnomiss, 1)
summary(nomiss)

##put everything back together
filledin_none = cbind(dontcolumn, nomiss)
summary(filledin_none)

##Outliers##
mahal = mahalanobis(filledin_none[ , -c(41:43)], 
                    colMeans(filledin_none[ , -c(41:43)], na.rm = TRUE),
                    cov(filledin_none[ , -c(41:43)], use="pairwise.complete.obs"))

summary(mahal)
cutoff = qchisq(.999,ncol(filledin_none[ , -c(41:43)])) 
summary(mahal < cutoff)
noout = filledin_none[ mahal < cutoff, ]

##additivity: correlations
correlations = cor(noout[,-c(41:43)], use="pairwise.complete.obs")
symnum(correlations)

##make the random stuff
random = rchisq(nrow(noout), 7)
##be sure here not to include the ID columns!
fake = lm(random~., data=noout[ , -c(41:43)])

##get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring
ELM <- rowSums(filledin_none[, c(1:40)])
summary(ELM)

##data sets
nooutnop = subset(noout, source != 'paper')
nomissnop = subset(filledin_none, source != 'paper')

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, Source == 'random')

overallmodel = '
RS =~ ELM1 + ELM2 + ELM3 + ELM4 + ELM5 + ELM6 + ELM7 + ELM8 +
ELM9 + ELM10 + ELM11 + ELM12 + ELM13 + ELM14 + ELM15 + ELM16 +
ELM17 + ELM18 + ELM19 + ELM20 + ELM21 + ELM22 + ELM23 + ELM24 +
ELM25 + ELM26 + ELM27 + ELM28 + ELM28 + ELM29 + ELM30 + ELM31 +
ELM32 + ELM33 + ELM34 + ELM35 + ELM36 + ELM37 + ELM38 + ELM39 +
ELM40' 


##fit for overall (excluding paper)
overall.fit = cfa(model = overallmodel, 
                  data = nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE) ##no heywood cases

##fit for random 
random.fit = cfa(overallmodel, 
                 data = random, 
                 meanstructure = TRUE)
summary(random.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)

##fit for not random 
notrandom.fit = cfa(overallmodel, 
                    data = notrandom, 
                    meanstructure = TRUE)
summary(notrandom.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)



multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = 'source', 
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)

## It broke down at Scalar Invariance 

partial = partialInvariance(multisteps, 
                            type = "intercepts")
##save only the results for easier viewing
interceptsfree = partial$results

##click on the name, sort by FREE CFI 
##release the biggest one first

multisteps2 = measurementInvariance(overallmodel,  
                                    data = nomissnop, 
                                    group = "source",
                                    strict = T,
                                    group.partial = c(ELM19~1 , ELM15~1 ,
                                                        ELM11~1, ELM23~1 ,
                                                      ELM9~1, ELM16~1, ELM_2~1))

## Allow for question 19, 15, 11, 23, 9, 16, and 2 to vary


##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint[5, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1,2,3)]), nrow(random), ncol(random[ , -c(1,2,3)]), PI, wherebroke)

tableprint[5, c(3, 4, 6, 8, 9)]

```


```{r ELMtable, echo = FALSE, results = 'asis'}
tableELM = matrix(NA, nrow = 7, ncol = 8)
tableELM[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableELM[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableELM[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableELM[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableELM[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.configural, fit.measures = fitused), 
                      "-")

tableELM[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.loadings)["cfi"] - fitmeasures(multisteps2$fit.configural)["cfi"])

tableELM[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.intercepts)["cfi"] - fitmeasures(multisteps2$fit.loadings)["cfi"])

tableELM[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.residuals)["cfi"] - fitmeasures(multisteps2$fit.intercepts)["cfi"])

tableELM[ , 3] = printnum(as.numeric(tableELM[ , 3]), big.mark = "")
tableELM[ , 5:8] = printnum(as.numeric(tableELM[ , 5:8]), gt1 = F, digits = 3)


kable(tableELM, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))

##check to make sure we use multisteps2 here instead of multisteps

```


```{r ELQ, include=FALSE}

elq = master[ , c(66:84, 14,955,956)]
summary(elq)

##reverse items 2, 7, 14, 18
names(elq)
master[ , c(2, 7, 14, 18)] = 6 - master[ , c(2, 7, 14, 18)]

####DATA SCREENING####

##Missing Data##

##Going by rows ONLY
notypos = elq
missing = apply(notypos[ , 1:19], 1, percentmiss) 
table(missing)

##replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##figure out the columns to exclude (survey data)
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(20:22)]
dontcolumn = replacepeople[ , c(20:22)]

nomiss = replacepeople

##Outliers##
mahal = mahalanobis(nomiss[ , -c(20:22)], 
                    colMeans(nomiss[ , -c(20:22)], na.rm = TRUE),
                    cov(nomiss[ , -c(20:22)], use="pairwise.complete.obs"))

summary(mahal)
cutoff = qchisq(.999,ncol(nomiss[ , -c(20:22)])) 
summary(mahal < cutoff)
noout = nomiss[ mahal < cutoff, ]

##additivity: correlations
correlations = cor(noout[,-c(20:22)], use="pairwise.complete.obs")
symnum(correlations)

##make the random stuff
random = rchisq(nrow(noout), 7)
##be sure here not to include the ID columns!
fake = lm(random~., data=noout[ , -c(20:22)])

##get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring 
ELQ <- rowSums(nomiss[, -c(20:22)])
summary(ELQ)

####overall cfa everyone together####

nooutnop = subset(noout, source != 'paper')
nomissnop = subset(nomiss, source != 'paper')

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, source == 'random')

overallmodel = '
ELQ =~ ELQ1 + ELQ2 + ELQ3 + ELQ4 + ELQ5 + ELQ6 + ELQ7 + ELQ8 + ELQ9 + ELQ10 + ELQ11 + ELQ12 + ELQ13 + ELQ14 +
ELQ15 + ELQ16 + ELQ17 + ELQ18 + ELQ19 + ELQ20 + ELQ21
'

##CFA

##fit for overall (excluding paper)
overall.fit = cfa(model = overallmodel, 
                  data = nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE) ##no heywood cases

##fit for random 
random.fit = cfa(overallmodel, 
                 data = random, 
                 meanstructure = TRUE)
summary(random.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)

##fit for not random 
notrandom.fit = cfa(overallmodel, 
                    data = notrandom, 
                    meanstructure = TRUE)
summary(notrandom.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)


multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = 'source', 
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)

##It broke down on the Scalar Invariance level

partial = partialInvariance(multisteps, 
                            type = "intercepts")
##save only the results for easier viewing
interceptsfree = partial$results

##click on the name, sort by FREE CFI
##release the biggest one first

multisteps2 = measurementInvariance(overallmodel, 
                                    data = nomissnop, 
                                    group = "source",
                                    strict = T,
                                    group.partial = c("ELQ19~1"))

##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint[6, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1,2,22)]), nrow(random), ncol(random[ , -c(1,2,22)]), PI, wherebroke)

tableprint[6, c(3, 4, 6, 8, 9)]

```


```{r ELQtable, echo = FALSE, results = 'asis'}
tableELQ = matrix(NA, nrow = 7, ncol = 8)
tableELQ[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableELQ[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableELQ[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableELQ[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableELQ[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.configural, fit.measures = fitused), 
                      "-")

tableELQ[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.loadings)["cfi"] - fitmeasures(multisteps2$fit.configural)["cfi"])

tableELQ[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.intercepts)["cfi"] - fitmeasures(multisteps2$fit.loadings)["cfi"])

tableELQ[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.residuals)["cfi"] - fitmeasures(multisteps2$fit.intercepts)["cfi"])

tableELQ[ , 3] = printnum(as.numeric(tableELQ[ , 3]), big.mark = "")
tableELQ[ , 5:8] = printnum(as.numeric(tableELQ[ , 5:8]), gt1 = F, digits = 3)


kable(tableELQ, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))

##double check to make sure we use multisteps2 instead of multisteps1

```


```{r EMAS, include=FALSE}

emas = master[ , c(606:617,14,955,956)]
summary(emas)

##No reverse coded items.

####DATA SCREENING####

##Missing Data##

##Going by rows ONLY
notypos = emas
names(notypos)
missing = apply(notypos[ , 1:12], 1, percentmiss) 
table(missing)

##Replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##figure out the columns to exclude (survey data)
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(13:15)]
dontcolumn = replacepeople[ , c(13:15)]

nomiss = replacepeople

##Outliers##
mahal = mahalanobis(nomiss[ , -c(13:15)], 
                    colMeans(nomiss[ , -c(13:15)], na.rm = TRUE),
                    cov(nomiss[ , -c(13:15)], use="pairwise.complete.obs"))

summary(mahal)
cutoff = qchisq(.999,ncol(nomiss[ , -c(13:15)])) 
summary(mahal < cutoff)
noout = nomiss[ mahal < cutoff, ]

##additivity: correlations
correlations = cor(noout[,-c(13:15)], use="pairwise.complete.obs")
symnum(correlations)

##make the random stuff
random = rchisq(nrow(noout), 7)
##be sure here not to include the ID columns!
fake = lm(random~., data=noout[ , -c(13:15)])

##get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring
##Sum up all columns 
EMAS <- rowSums(nomiss[1:12])
summary(EMAS)

####CFA####
##subsetting data
#Zero = notrandom, One = random, Two = paper
nooutnop = subset(noout, source != 'paper')
nomissnop = subset(nomiss, source != 'paper')

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, source == 'random')

####overall model for everyone together##
overallmodel = '
EMAS =~
EMAS1 + EMAS2 + EMAS3 + EMAS4 + EMAS5 + EMAS6 + EMAS7 
+ EMAS8 + EMAS9 + EMAS10 + EMAS11 + EMAS12
'

overall.fit = cfa(model = overallmodel, 
                  data=nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

##random
overall.fit.r = cfa(overallmodel, 
                    data=random, 
                    meanstructure = TRUE)

summary(overall.fit.r, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

##notrandom
overall.fit.nr = cfa(overallmodel, 
                     data=notrandom, 
                     meanstructure = TRUE)

summary(overall.fit.nr, 
        standardized=TRUE,
        rsquare=TRUE, 
        fit.measure = TRUE)


####multi group testing####
###measurement invariance

multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = "source",
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)

##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint[7, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1,2,15)]), nrow(random), ncol(random[ , -c(1,2,15)]), PI, wherebroke)

tableprint[7, c(3, 4, 6, 8, 9)]

```


```{r EMAStable, echo = FALSE, results = 'asis'}
tableEMAS = matrix(NA, nrow = 7, ncol = 8)
tableEMAS[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableEMAS[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableEMAS[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableEMAS[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableEMAS[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.configural, fit.measures = fitused), 
                      "-")

tableEMAS[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.loadings)["cfi"] - fitmeasures(multisteps$fit.configural)["cfi"])

tableEMAS[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.intercepts)["cfi"] - fitmeasures(multisteps$fit.loadings)["cfi"])

tableEMAS[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.residuals)["cfi"] - fitmeasures(multisteps$fit.intercepts)["cfi"])

tableEMAS[ , 3] = printnum(as.numeric(tableEMAS[ , 3]), big.mark = "")
tableEMAS[ , 5:8] = printnum(as.numeric(tableEMAS[ , 5:8]), gt1 = F, digits = 3)


kable(tableEMAS, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))

```


```{r EMS, include=FALSE}

ems = master[ , c(471:490, 14,955,956)]
summary(ems)
names(ems)

##Reverse Code. 1, 4, 7, 8, 9, 10, 13, 17, 19
##the paper says that seven of them were reverse coded but doesn't say which
##these items definitely are reversed given the histograms
master[ , c(1, 4, 7:10, 13, 17, 19)] = 6 - master[ , c(1, 4, 7:10, 13, 17, 19)] 

####DATA SCREENING####

##Missing Data##

##Going by rows ONLY
##here I excluded the first two columns because they were 
##included for everyone as IDs, so I don't want to count that
##as part of the percent toward what they did
notypos = ems
missing = apply(notypos[ , 1:20], 1, percentmiss) 
table(missing)

##replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##figure out the columns to exclude (survey data)
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(21:23)]
dontcolumn = replacepeople[ , c(21:23)]

##let's mice it!
tempnomiss = mice(replacecolumn)
nomiss = complete(tempnomiss, 1)
summary(nomiss)

##put everything back together
filledin_none = cbind(dontcolumn, nomiss)
summary(filledin_none)

##Outliers##
mahal = mahalanobis(filledin_none[ , -c(21:23)], 
                    colMeans(filledin_none[ , -c(21:23)], na.rm = TRUE),
                    cov(filledin_none[ , -c(21:23)], use="pairwise.complete.obs"))

cutoff = qchisq(.999,ncol(filledin_none[ , -c(21:23)])) 
summary(mahal < cutoff)
noout = filledin_none[ mahal < cutoff, ]

##additivity: correlations
correlations = cor(noout[,-c(21:23)], use="pairwise.complete.obs")
symnum(correlations)

##make the random stuff
random = rchisq(nrow(noout), 7)
fake = lm(random~., data=noout[ , -c(21:23)])

##get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring 
EMS <- rowSums(filledin_none[, c(2,6,7,9,10,15,16,18,19,20)])
summary(EMS)

####mgcfa####

nooutnop = subset(noout, source != 'paper')
nomissnop = subset(filledin_none, source != 'paper')

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, source == 'random')


overallmodel = '
EMS =~ EMS1 + EMS6 + EMS6  + EMS8 + EMS9 +
EMS14 + EMS15 + EMS17 + EMS18 + EMS19'

##fit for overall (excluding paper)
overall.fit = cfa(model = overallmodel, 
                  data = nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE) ##no heywood cases

##fit for random 
random.fit = cfa(overallmodel, 
                 data = random, 
                 meanstructure = TRUE)
summary(random.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)

##fit for not random 
notrandom.fit = cfa(overallmodel, 
                    data = notrandom, 
                    meanstructure = TRUE)
summary(notrandom.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)


multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = 'source', 
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)

##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint[8, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1:3)]), nrow(random), ncol(random[ , -c(1:3)]), PI, wherebroke)

tableprint[8, c(3, 4, 6, 8, 9)]


```


```{r EMStable, echo = FALSE, results = 'asis'}
tableEMS = matrix(NA, nrow = 7, ncol = 8)
tableEMS[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableEMS[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableEMS[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableEMS[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableEMS[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.configural, fit.measures = fitused), 
                      "-")

tableEMS[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.loadings)["cfi"] - fitmeasures(multisteps$fit.configural)["cfi"])

tableEMS[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.intercepts)["cfi"] - fitmeasures(multisteps$fit.loadings)["cfi"])

tableEMS[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.residuals)["cfi"] - fitmeasures(multisteps$fit.intercepts)["cfi"])

tableEMS[ , 3] = printnum(as.numeric(tableEMS[ , 3]), big.mark = "")
tableEMS[ , 5:8] = printnum(as.numeric(tableEMS[ , 5:8]), gt1 = F, digits = 3)


kable(tableEMS, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))

```


```{r ES, include=FALSE}

es = master [, c(20:65,14,955,956)]
summary(es)

##Reverse Code. 2, 15, 21, 26, 36
names(es)
es$ES2 = recode(es$ES2, "1='7'; 2='6'; 3='5'; 4='4'; 5='3'; 6='2'; 7='1'")
es$ES15 = recode(es$ES15, "1='7'; 2='6'; 3='5'; 4='4'; 5='3'; 6='2'; 7='1'")
es$ES21 = recode(es$ES21, "1='7'; 2='6'; 3='5'; 4='4'; 5='3'; 6='2'; 7='1'")
es$ES26 = recode(es$ES26, "1='7'; 2='6'; 3='5'; 4='4'; 5='3'; 6='2'; 7='1'")
es$ES36 = recode(es$ES36, "1='7'; 2='6'; 3='5'; 4='4'; 5='3'; 6='2'; 7='1'")

####DATA SCREENING####

##Missing Data##

##Going by rows ONLY
##here I excluded the first two columns because they were 
##included for everyone as IDs, so I don't want to count that
##as part of the percent toward what they did
notypos = es
missing = apply(notypos[ , 1:46], 1, percentmiss) 
table(missing)

##replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##figure out the columns to exclude (survey data)
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(47:49)]
dontcolumn = replacepeople[ , c(47:49)]

##let's mice it!
tempnomiss = mice(replacecolumn)
nomiss = complete(tempnomiss, 1)
summary(nomiss)

##put everything back together
filledin_none = cbind(dontcolumn, nomiss)
summary(filledin_none)


##Outliers##
mahal = mahalanobis(filledin_none[ , -c(47:49)], 
                    colMeans(filledin_none[ , -c(47:49)], na.rm = TRUE),
                    cov(filledin_none[ , -c(47:49)], use="pairwise.complete.obs"))

summary(mahal)
cutoff = qchisq(.999,ncol(filledin_none[ , -c(47:49)])) 
summary(mahal < cutoff)
noout = filledin_none[ mahal < cutoff, ]

##additivity: correlations
correlations = cor(noout[,-c(47:49)], use="pairwise.complete.obs")
symnum(correlations)

##make the random stuff
random = rchisq(nrow(noout), 7)
##be sure here not to include the ID columns!
fake = lm(random~., data=noout[ , -c(47:49)])

#get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

#MGCFA

##Factoring source##
#Zero = notrandom, One = random, Two = paper
nooutnop = subset(noout, source != 'paper')
nomissnop = subset(filledin_none, source != 'paper')

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, source == 'random')

##Model 
overallmodel = '
SelfDistance =~ ES3 + ES5 + ES19 + ES32 + ES40 + ES42 + ES43 + ES44
SelfTrans =~ ES2 + ES4 + ES11 + ES12 + ES13 + ES14 + ES21 + ES27 + ES33 + ES34 + ES35 + ES36 + ES41 + ES45
Freedom =~ ES9 + ES10 + ES15 + ES17 + ES18 + ES23 + ES24 + ES26 + ES28 + ES31 + ES46
Responsibility =~ ES1 + ES6 + ES7 + ES8 + ES16 + ES20 + ES22 + ES25 + ES29 + ES30 + ES37 + ES38 + ES39
'
overall.fit = cfa(overallmodel, 
                  data=nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

####separate group models####
##notrandom
overall.fit.nr = cfa(overallmodel, 
                     data=notrandom, 
                     meanstructure = TRUE)

summary(overall.fit.nr, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)

##random
overall.fit.r = cfa(overallmodel, 
                    data=random, 
                    meanstructure = TRUE)

summary(overall.fit.r, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE)


####multi group testing####
###measurement invariance

multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = "source",
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)

##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint[9, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1:3)]), nrow(random), ncol(random[ , -c(1:3)]), PI, wherebroke)

tableprint[9, c(3, 4, 6, 8, 9)]

```


```{r EStable, echo = FALSE, results = 'asis'}
tableES = matrix(NA, nrow = 7, ncol = 8)
tableES[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableES[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableES[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableES[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableES[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.configural, fit.measures = fitused), 
                      "-")

tableES[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.loadings)["cfi"] - fitmeasures(multisteps$fit.configural)["cfi"])

tableES[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.intercepts)["cfi"] - fitmeasures(multisteps$fit.loadings)["cfi"])

tableES[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps$fit.residuals)["cfi"] - fitmeasures(multisteps$fit.intercepts)["cfi"])

tableES[ , 3] = printnum(as.numeric(tableES[ , 3]), big.mark = "")
tableES[ , 5:8] = printnum(as.numeric(tableES[ , 5:8]), gt1 = F, digits = 3)


kable(tableES, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))

```


```{r FOM, include=FALSE}

FOM = master[ , c(618:629, 14, 955,956)]
names(FOM)
summary(master)

##fix qualtrics coding that's incorrect 1-5 instead of 0-4
FOM[ , c(1:12)] = master[ , c(1:12)] - 1

##Reverse Code. 2, 4, 5, 7, 9 , 11
FOM[ , c(2, 4, 5, 7, 9, 11)] = 4 - FOM[ , c(2, 4, 5, 7, 9, 11)] 
summary(master)

####DATA SCREENING####

##Missing Data##

##Going by rows ONLY
##here I excluded the first two columns because they were 
##included for everyone as IDs, so I don't want to count that
##as part of the percent toward what they did
notypos = FOM
missing = apply(notypos[ , 1:12], 1, percentmiss) 
table(missing)

##replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##figure out the columns to exclude (survey data)
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(13:15)]
dontcolumn = replacepeople[ , c(13:15)]

nomiss = replacepeople

##Outliers##
mahal = mahalanobis(nomiss[ , -c(13:15)], 
                    colMeans(nomiss[ , -c(13:15)], na.rm = TRUE),
                    cov(nomiss[ , -c(13:15)], use="pairwise.complete.obs"))

summary(mahal)
cutoff = qchisq(.999,ncol(nomiss[ , -c(13:15)])) 
summary(mahal < cutoff)
noout = nomiss[ mahal < cutoff, ]

##additivity: correlations
correlations = cor(noout[,-c(13:15)], use="pairwise.complete.obs")
symnum(correlations)

##make the random stuff
random = rchisq(nrow(noout), 7)
##be sure here not to include the ID columns!
fake = lm(random~., data=noout[ , -c(13:15)])

##get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring
FOM <- rowSums(nomiss[, c(1:12)])
summary(FOM)

nooutnop = subset(noout, source != 'paper')
nomissnop = subset(nomiss, source != 'paper')

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, source == 'random')

overallmodel = '
FOM =~ FOM1 + FOM2 + FOM3 + FOM4 + FOM5 + FOM6 + FOM7 +
FOM8 + FOM9 + FOM10 + FOM11 + FOM12
'

##fit for overall (excluding paper)
overall.fit = cfa(model = overallmodel, 
                  data = nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE) ##no heywood cases

##fit for random 
random.fit = cfa(overallmodel, 
                 data = random, 
                 meanstructure = TRUE)
summary(random.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)

##fit for not random 
notrandom.fit = cfa(overallmodel, 
                    data = notrandom, 
                    meanstructure = TRUE)
summary(notrandom.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)

multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = 'source', 
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)

##Broke Down on Metric Invariance 

partial = partialInvariance(multisteps, 
                            type = "loadings")
##save only the results for easier viewing
loadinsfree = partial$results

multisteps2 = measurementInvariance(overallmodel, 
                                    data = nomissnop, 
                                    group = "source",
                                    strict = T,
                                    group.partial = c("FOM2=~FOM2"))

## Allow for question 2 to vary 

##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint[10, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1:2,15)]), nrow(random), ncol(random[ , -c(1:2,15)]), PI, wherebroke)

tableprint[10, c(3, 4, 6, 8, 9)]


```


```{r FOMtable, echo = FALSE, results = 'asis'}
tableFOM = matrix(NA, nrow = 7, ncol = 8)
tableFOM[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableFOM[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableFOM[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableFOM[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableFOM[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.configural, fit.measures = fitused), 
                      "-")

tableFOM[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.loadings)["cfi"] - fitmeasures(multisteps2$fit.configural)["cfi"])

tableFOM[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.intercepts)["cfi"] - fitmeasures(multisteps2$fit.loadings)["cfi"])

tableFOM[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.residuals)["cfi"] - fitmeasures(multisteps2$fit.intercepts)["cfi"])

tableFOM[ , 3] = printnum(as.numeric(tableFOM[ , 3]), big.mark = "")
tableFOM[ , 5:8] = printnum(as.numeric(tableFOM[ , 5:8]), gt1 = F, digits = 3)


kable(tableFOM, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))
```


```{r GLPS, include=FALSE}

glps = master[ , c(491:505,14,955,956)]
summary(glps)

##Reverse Code. 5 8 and 13
glps[ , c(5, 8, 13)] =  8 - glps[ , c(5, 8, 13)]

####DATA SCREENING####

##Missing Data##

##Going by rows ONLY
##here I excluded the first two columns because they were 
##included for everyone as IDs, so I don't want to count that
##as part of the percent toward what they did
notypos = glps
names(notypos)
missing = apply(notypos[ , 1:15], 1, percentmiss) 
table(missing)

##replace only the data that you should
replacepeople = notypos[ missing <= 5 , ]  
dontpeople = notypos[ missing > 5 , ]

##figure out the columns to exclude (survey data)
apply(replacepeople, 2, percentmiss)
replacecolumn = replacepeople[ , -c(16:18)]
dontcolumn = replacepeople[ , c(16:18)]

nomiss = replacepeople

##Outliers##
mahal = mahalanobis(nomiss[ , -c(16:18)], 
                    colMeans(nomiss[ , -c(16:18)], na.rm = TRUE),
                    cov(nomiss[ , -c(16:18)], use="pairwise.complete.obs"))

summary(mahal)
cutoff = qchisq(.999,ncol(nomiss[ , -c(16:18)])) 
summary(mahal < cutoff)
noout = nomiss[ mahal < cutoff, ]

##additivity: correlations
correlations = cor(noout[,-c(16:18)], use="pairwise.complete.obs")
symnum(correlations)

##make the random stuff
random = rchisq(nrow(noout), 7)
##be sure here not to include the ID columns!
fake = lm(random~., data=noout[ , -c(16:18)])

##get the linearity plot
##create the standardized residuals
standardized = rstudent(fake)
{qqnorm(standardized)
abline(0,1)}

##multivariate normality
hist(standardized, breaks=15)

##homogeneity and homoscedaticity
fitvalues = scale(fake$fitted.values)
{plot(fitvalues, standardized) 
abline(0,0)
abline(v = 0)}

##Scoring
GLPS <- rowSums(nomiss[, c(1:15)])
summary(GLPS)

##CFA

nooutnop = subset(noout, source != 'paper')
nomissnop = subset(nomiss, source != 'paper')

notrandom = subset(nomissnop, source == 'not random')
random = subset(nomissnop, source == 'random')

overallmodel = '
GLPS =~ GLPS1 + GLPS2 + GLPS3 + GLPS4 + GLPS5 + GLPS6 + GLPS7
+ GLPS8 + GLPS9 + GLPS10 + GLPS11 + GLPS12 + GLPS13 + GLPS14 + GLPS15
'

##fit for overall 
overall.fit = cfa(model = overallmodel, 
                  data = nomissnop, 
                  meanstructure = TRUE)

summary(overall.fit, 
        standardized=TRUE, 
        rsquare=TRUE, 
        fit.measure = TRUE) 

##fit for random 
random.fit = cfa(overallmodel, 
                 data = random, 
                 meanstructure = TRUE)
summary(random.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)

##fit for not random 
notrandom.fit = cfa(overallmodel, 
                    data = notrandom, 
                    meanstructure = TRUE)
summary(notrandom.fit, 
        standardized = TRUE, 
        rsquare = TRUE, 
        fit.measure = TRUE)


multisteps = measurementInvariance(overallmodel, 
                                   data = nomissnop, 
                                   group = 'source', 
                                   strict = T)

fitmeasures(multisteps$fit.configural)
fitmeasures(multisteps$fit.loadings)
fitmeasures(multisteps$fit.intercepts)
fitmeasures(multisteps$fit.residuals)

##It broke down on the Strict Invariance level

partial = partialInvariance(multisteps, 
                            type = "residuals")

##save only the results for easier viewing
residualsfree = partial$results

##click on the name, sort by FREE CFI
##release the biggest one first

multisteps2 = measurementInvariance(overallmodel, 
                                    data = nomissnop, 
                                    group = "source",
                                    strict = T,
                                    group.partial = c(GLPS3~~GLPS3))
##Removing question 3 did it. 

##scale name, number of scale points, sample size by group (2 columns), reliability, number of items, number of subscales
##did it break (y/n), where it broke, partial invariance (y/n), citation counts, publication year, 

tableprint[11, c(3, 4, 6, 8, 9)] = c(nrow(notrandom[, -c(1:2,18)]), nrow(random), ncol(random[ , -c(1:2,18)]), PI, wherebroke)

tableprint[11, c(3, 4, 6, 8, 9)]

```


```{r GLPStable, echo = FALSE, results = 'asis'}
tableGLPS = matrix(NA, nrow = 7, ncol = 8)
tableGLPS[ , 1] = c("Overall Model", "Random", "Not Random", 
                   "Configural", "Metric", "Scalar", "Strict")

fitused = c("chisq", "df", "rmsea", "srmr", "cfi")

tableGLPS[1, 2:8 ] = c(nrow(nomissnop), 
                      fitmeasures(overall.fit, fit.measures = fitused), 
                      "-")
tableGLPS[2, 2:8] = c(nrow(random), 
                      fitmeasures(overall.fit.r, fit.measures = fitused), 
                      "-")

tableGLPS[3, 2:8] = c(nrow(notrandom), 
                      fitmeasures(overall.fit.nr, fit.measures = fitused), 
                      "-")

tableGLPS[4, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.configural, fit.measures = fitused), 
                      "-")

tableGLPS[5, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.loadings, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.loadings)["cfi"] - fitmeasures(multisteps2$fit.configural)["cfi"])

tableGLPS[6, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.intercepts, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.intercepts)["cfi"] - fitmeasures(multisteps2$fit.loadings)["cfi"])

tableGLPS[7, 2:8] = c(nrow(nomissnop), 
                      fitmeasures(multisteps2$fit.residuals, fit.measures = fitused), 
                      fitmeasures(multisteps2$fit.residuals)["cfi"] - fitmeasures(multisteps2$fit.intercepts)["cfi"])

tableGLPS[ , 3] = printnum(as.numeric(tableGLPS[ , 3]), big.mark = "")
tableGLPS[ , 5:8] = printnum(as.numeric(tableGLPS[ , 5:8]), gt1 = F, digits = 3)


kable(tableGLPS, 
      col.names = c("Model", "N", "Chi-Square", 
                       "df", "RMSEA", "SRMR", "CFI", "Change CFI"))

```


```{r LAP, include=FALSE}
master = read.csv("Meaning_Scales_LAP_Reker_RR_RN_Paper.csv")
summary(master)



```

```{r LAPtable, echo = FALSE, results = 'asis'}

```

```{r LAP-R, include=FALSE}

```

```{r LAP-Rtable, echo = FALSE, results = 'asis'}

```

```{r LAS, include = FALSE}

```

```{r LAStable, echo=FALSE, results='asis'}

```

```{r LET, include=FALSE}

```

```{r LETtable, echo=FALSE, results='asis'}

```

```{r LPQ, include=FALSE}

```

```{r LPQtable, echo=FALSE, results='asis'}

```

```{r LRI, include=FALSE}

```

```{r LRItable, echo=FALSE, results='asis'}

```

```{r MAPA, include=FALSE}

```

```{r MAPAtable, echo=FALSE, results='asis'}

```

```{r Meaning, include=FALSE}

```

```{r Meaningtable, echo=FALSE, results='asis'}

```

```{r MLM, include=FALSE}

```

```{r MLMtable, echo=FALSE, results='asis'}

```

```{r MIL-Jim, include=FALSE}

```

```{r MIL-Jimtable, echo=FALSE, results='asis'}

```

```{r MIL-Kernes, include=FALSE}

```

```{r MIL-Kernestable, echo=FALSE, results='asis'}

```

```{r MIL-Steger, include=FALSE}

```

```{r MIL-Stegertable, echo=FALSE, results='asis'}

```

```{r MIL-Tomich, include=FALSE}

```

```{r MIL-Tomichtable, echo=FALSE, results='asis'}

```

```{r MIL-Warner, include=FALSE}

```

```{r MIL-Warnertable, echo=FALSE, results='asis'}

```

```{r MILI, include=FALSE}

```

```{r MILItable, echo=FALSE, results='asis'}

```

```{r MMS, include=FALSE}

```

```{r MMStable, echo=FALSE, results='asis'}

```

```{r MM, include=FALSE}

```

```{r MMtable, echo=FALSE, results='asis'}

```

```{r NoM, include=FALSE}

```

```{r NoMtable, echo=FALSE, results='asis'}

```

```{r OTH, include=FALSE}

```

```{r OTHtable, echo=FALSE, results='asis'}

```

```{r PVS, include=FALSE}

```

```{r PVStable, echo=FALSE, results='asis'}

```

```{r PIL, include=FALSE}

```

```{r PILtable, echo=FALSE, results='asis'}

```

```{r PILshort, include=FALSE}

```

```{r PILshorttable, echo=FALSE, results='asis'}

```

```{r PPM&PMP, include=FALSE}

```

```{r PPM&PMPtable, echo=FALSE, results='asis'}

```

```{r PVSH, include=FALSE}

```

```{r PVSHtable, echo=FALSE, results='asis'}

```

```{r QE, include=FALSE}

```

```{r QEtable, echo=FALSE, results='asis'}

```

```{r RS14, include=FALSE}

```

```{r RS14table, echo=FALSE, results='asis'}

```

```{r SWL, include=FALSE}

```

```{r SWLtable, echo=FALSE, results='asis'}

```

```{r SONG, include=FALSE}

```

```{r SONGtable, echo=FALSE, results='asis'}

```

```{r SOC, include=FALSE}

```

```{r SOCtable, echo=FALSE, results='asis'}

```

```{r SOM, include=FALSE}

```

```{r SOMtable, echo=FALSE, results='asis'}

```

```{r SMS, include=FALSE}

```

```{r SMStable, echo=FALSE, results='asis'}

```

```{r STMS, include=FALSE}

```

```{r STMStable, echo=FALSE, results='asis'}

```

```{r VOL, include=FALSE}

```

```{r VOLtable, echo=FALSE, results='asis'}

```

```{r WBS, include=FALSE}

```

```{r WBStable, echo=FALSE, results='asis'}

```


##ideas

for the paper:
- compare # times broken down and where based on:
-- sample size 
-- type of data (likert, true/false)
-- number of items or subscales
-- previous reliability 

test test test
